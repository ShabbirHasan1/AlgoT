{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from datetime import datetime, timezone, timedelta, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import time as tm\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import timeit\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2020\n",
    "month = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALGO1\\AppData\\Local\\Temp\\2\\ipykernel_14968\\410421955.py:1: DtypeWarning: Columns (8,9,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'data/{year}/NiftySpotData-{month}{year}-1min-Signal-Expiry.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'data/{year}/NiftySpotData-{month}{year}-1min-Signal-Expiry.csv')\n",
    "# df = pd.read_csv(f'/home/algolinux/7/D$/HirakDrive/workspace/GitHub/Endovia/data/{year}/NiftySpotData-{year}-1min-Signal-Expiry.csv')\n",
    "\n",
    "df[\"Datetime\"] = pd.to_datetime(df[\"Datetime\"], format='%Y-%m-%d %H:%M:%S%z')\n",
    "df['closest_expiry'] = pd.to_datetime(df['closest_expiry'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# # Convert 'Datetime' to datetime and add timezone information '+05:30'\n",
    "# df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "# df['Datetime'] = df['Datetime'].dt.strftime('%Y-%m-%d %H:%M:%S') + '+05:30'\n",
    "\n",
    "# # Convert 'closest_expiry' to datetime and add time component '00:00:00+00:00'\n",
    "# df['closest_expiry'] = pd.to_datetime(df['closest_expiry'], format='%Y-%m-%d')\n",
    "# df['closest_expiry'] = df['closest_expiry'].dt.strftime('%Y-%m-%d') + ' 00:00:00+00:00'\n",
    "\n",
    "# # Convert 'Datetime' back to datetime with timezone information\n",
    "# df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# # Convert 'closest_expiry' back to datetime with timezone information\n",
    "# df['closest_expiry'] = pd.to_datetime(df['closest_expiry'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "\n",
    "try:\n",
    "    # df drop PL PH, PL_val, PH_val, slope_ph, slope_pl, upper, lower, upos, dnos, IsPivotHigh\n",
    "    df.drop(['PL', 'PH', 'PL_val', 'PH_val', 'slope_ph', 'slope_pl', 'upper', 'lower', 'upos', 'dnos', 'IsPivotHigh', 'Slope'], axis=1, inplace=True)\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize all columns with NaN\n",
    "df = df.assign(\n",
    "    position='', atmSP=np.nan, wingCall=np.nan, wingPut=np.nan, legPriceOrignal1=np.nan, legPriceOrignal2=np.nan,\n",
    "    legPriceOrignal3=np.nan, legPriceOrignal4=np.nan, lpos1=np.nan, lpos2=np.nan, lpos3=np.nan, lpos4=np.nan,\n",
    "    legAfterPos1=np.nan, legAfterPos2=np.nan, legAfterPos3=np.nan, legAfterPos4=np.nan, legAfterPosDiff1=np.nan,\n",
    "    legAfterPosDiff2=np.nan, legAfterPosDiff3=np.nan, legAfterPosDiff4=np.nan, legPriceFinal1=np.nan,\n",
    "    legPriceFinal2=np.nan, legPriceFinal3=np.nan, legPriceFinal4=np.nan, m2m1=np.nan, m2m2=np.nan, m2m3=np.nan,\n",
    "    m2m4=np.nan, totalPL=0, cumReturns=0, balance=0\n",
    ")\n",
    "\n",
    "# only keep values between 9:15 to 15:30\n",
    "df = df[(df['Datetime'].dt.time >= time(9, 15)) & (df['Datetime'].dt.time <= time(15, 30))]\n",
    "\n",
    "# drop rows with same Datetime\n",
    "df.drop_duplicates(subset='Datetime', keep='first', inplace=True)\n",
    "\n",
    "# reset df index\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for missing optionsData by dropping the rows from df where Datetime is\n",
    "# dates_to_drop = ['2023-02-16', '2023-03-07', '2023-03-30', '2023-04-04', '2023-09-19', '2023-04-25', '2023-01-20', '2023-10-22', '2023-10-24']\n",
    "# dates_to_drop = ['2022-09-22']\n",
    "# dates_to_drop = ['2021-01-08', '2021-02-24', '2021-07-16', '2021-08-02', '2021-11-03', '2021-11-04']\n",
    "# dates_to_drop = ['2020-01-31', '2020-03-13']\n",
    "dates_to_drop = ['2024-03-02']\n",
    "for date in dates_to_drop:\n",
    "    df = df[df['Datetime'].dt.date != pd.to_datetime(date).date()]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>ama</th>\n",
       "      <th>rsi</th>\n",
       "      <th>atr</th>\n",
       "      <th>signal</th>\n",
       "      <th>closest_expiry</th>\n",
       "      <th>...</th>\n",
       "      <th>legPriceFinal2</th>\n",
       "      <th>legPriceFinal3</th>\n",
       "      <th>legPriceFinal4</th>\n",
       "      <th>m2m1</th>\n",
       "      <th>m2m2</th>\n",
       "      <th>m2m3</th>\n",
       "      <th>m2m4</th>\n",
       "      <th>totalPL</th>\n",
       "      <th>cumReturns</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17478.10</td>\n",
       "      <td>17387.15</td>\n",
       "      <td>17387.15</td>\n",
       "      <td>17462.35</td>\n",
       "      <td>2022-01-03 09:15:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.95</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17451.45</td>\n",
       "      <td>17428.40</td>\n",
       "      <td>17428.40</td>\n",
       "      <td>17450.55</td>\n",
       "      <td>2022-01-03 09:16:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.95</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17459.55</td>\n",
       "      <td>17442.05</td>\n",
       "      <td>17450.05</td>\n",
       "      <td>17457.70</td>\n",
       "      <td>2022-01-03 09:17:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.95</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17465.75</td>\n",
       "      <td>17455.30</td>\n",
       "      <td>17455.95</td>\n",
       "      <td>17464.55</td>\n",
       "      <td>2022-01-03 09:18:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.95</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474.65</td>\n",
       "      <td>17462.15</td>\n",
       "      <td>17465.25</td>\n",
       "      <td>17473.20</td>\n",
       "      <td>2022-01-03 09:19:00+05:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.95</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2022-01-05 00:00:00+00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       High       Low      Open     Close                  Datetime  ama  rsi  \\\n",
       "0  17478.10  17387.15  17387.15  17462.35 2022-01-03 09:15:00+05:30  NaN  NaN   \n",
       "1  17451.45  17428.40  17428.40  17450.55 2022-01-03 09:16:00+05:30  NaN  NaN   \n",
       "2  17459.55  17442.05  17450.05  17457.70 2022-01-03 09:17:00+05:30  NaN  NaN   \n",
       "3  17465.75  17455.30  17455.95  17464.55 2022-01-03 09:18:00+05:30  NaN  NaN   \n",
       "4  17474.65  17462.15  17465.25  17473.20 2022-01-03 09:19:00+05:30  NaN  NaN   \n",
       "\n",
       "     atr signal            closest_expiry  ... legPriceFinal2 legPriceFinal3  \\\n",
       "0  90.95   Hold 2022-01-05 00:00:00+00:00  ...            NaN            NaN   \n",
       "1  90.95   Hold 2022-01-05 00:00:00+00:00  ...            NaN            NaN   \n",
       "2  90.95   Hold 2022-01-05 00:00:00+00:00  ...            NaN            NaN   \n",
       "3  90.95   Hold 2022-01-05 00:00:00+00:00  ...            NaN            NaN   \n",
       "4  90.95   Hold 2022-01-05 00:00:00+00:00  ...            NaN            NaN   \n",
       "\n",
       "   legPriceFinal4  m2m1  m2m2  m2m3  m2m4  totalPL  cumReturns  balance  \n",
       "0             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "1             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "2             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "3             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "4             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionsData = pd.read_csv(f'data/{year}/NiftyOptionsData-{month}{year}-1min.csv')\n",
    "# optionsData.rename(columns={'Expirydate': 'ExpiryDate'}, inplace=True)\n",
    "\n",
    "# #make a new column named Instrument Type \n",
    "# optionsData['InstrumentType'] = optionsData['Ticker'].apply(lambda x: 'CE' if x[-6] == 'C' else 'PE') \n",
    "\n",
    "# #save as csv file with same name\n",
    "# optionsData.to_csv(f'data/{year}/NiftyOptionsData-{month}{year}-1min.csv', index=False)\n",
    "\n",
    "# optionsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print unique Ticker values\n",
    "# set(optionsData['Ticker'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ExpiryDate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ExpiryDate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# optionsData['Datetime'] = optionsData['Datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], format='%Y-%m-%d %H:%M:%S')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43moptionsData\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpiryDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(optionsData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpiryDate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ExpiryDate'"
     ]
    }
   ],
   "source": [
    "optionsData = pd.read_csv(f'data/{year}/NiftyOptionsData-{month}{year}-1min.csv')\n",
    "# optionsData = pd.read_csv(f'/home/algolinux/7/D$/HirakDrive/workspace/GitHub/Endovia/data/{year}/NiftyOptionsData-{year}-1min.csv')\n",
    "optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "# optionsData['Datetime'] = optionsData['Datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "# optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "optionsData['ExpiryDate'] = pd.to_datetime(optionsData['ExpiryDate'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "optionsData['ExpiryDate'] = optionsData['ExpiryDate'].dt.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "optionsData['ExpiryDate'] = pd.to_datetime(optionsData['ExpiryDate'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "\n",
    "\n",
    "optionsData = optionsData.sort_values(by='Datetime')\n",
    "optionsData.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionsData = pd.read_csv(f'data/{year}/NiftyOptionsData-May{year}-1min.csv')\n",
    "\n",
    "# # Drop unnecessary column if exists\n",
    "# if 'Unnamed: 0' in optionsData.columns:\n",
    "#     optionsData.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "# # Convert the 'Datetime' column to datetime format with timezone information\n",
    "# optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# # Remove timezone information for filtering purposes (convert to naive datetime)\n",
    "# optionsData['Datetime'] = optionsData['Datetime'].dt.tz_localize(None)\n",
    "\n",
    "# # Convert the 'Expiry Date' column to datetime with timezone information\n",
    "# optionsData['Expiry Date'] = pd.to_datetime(optionsData['Expiry Date'], format='%Y-%m-%d %H:%M:%S %z')\n",
    "\n",
    "# # Set the time component to '00:00:00' and timezone to '+00:00'\n",
    "# optionsData['Expiry Date'] = optionsData['Expiry Date'].dt.tz_convert('UTC').dt.normalize()\n",
    "\n",
    "# # Rename 'Strike Price' to 'Strike'\n",
    "# optionsData.rename(columns={'Strike Price': 'Strike'}, inplace=True)\n",
    "\n",
    "# # Ensure 'Datetime' is in datetime format\n",
    "# optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], errors='coerce')\n",
    "\n",
    "# # Keep only data where time is ending in 00, 15, 30, 45 minutes\n",
    "# optionsData = optionsData[optionsData['Datetime'].dt.minute % 15 == 0]\n",
    "\n",
    "# # Sort the data by 'Datetime' and reset the index\n",
    "# optionsData = optionsData.sort_values(by='Datetime')\n",
    "# optionsData.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Save the cleaned data back to a CSV file\n",
    "# optionsData.to_csv(f'data/{year}/NiftyOptionsData-May{year}-1min.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ExpiryDate</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Instrument Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03 09:15:00</td>\n",
       "      <td>135.50</td>\n",
       "      <td>135.50</td>\n",
       "      <td>135.50</td>\n",
       "      <td>135.50</td>\n",
       "      <td>NIFTY03FEB2216050PE.NFO</td>\n",
       "      <td>2022-02-03 00:00:00+00:00</td>\n",
       "      <td>16050.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03 09:15:00</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.45</td>\n",
       "      <td>NIFTY06JAN2215500PE.NFO</td>\n",
       "      <td>2022-01-06 00:00:00+00:00</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03 09:15:00</td>\n",
       "      <td>55.20</td>\n",
       "      <td>57.00</td>\n",
       "      <td>53.90</td>\n",
       "      <td>54.75</td>\n",
       "      <td>NIFTY13JAN2217750CE.NFO</td>\n",
       "      <td>2022-01-13 00:00:00+00:00</td>\n",
       "      <td>17750.0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-03 09:15:00</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.20</td>\n",
       "      <td>NIFTY06JAN2215100PE.NFO</td>\n",
       "      <td>2022-01-06 00:00:00+00:00</td>\n",
       "      <td>15100.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-03 09:15:00</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.15</td>\n",
       "      <td>NIFTY06JAN2215150PE.NFO</td>\n",
       "      <td>2022-01-06 00:00:00+00:00</td>\n",
       "      <td>15150.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime    Open    High     Low   Close  \\\n",
       "0 2022-01-03 09:15:00  135.50  135.50  135.50  135.50   \n",
       "1 2022-01-03 09:15:00    1.70    1.70    1.40    1.45   \n",
       "2 2022-01-03 09:15:00   55.20   57.00   53.90   54.75   \n",
       "3 2022-01-03 09:15:00    1.45    1.45    0.95    1.20   \n",
       "4 2022-01-03 09:15:00    1.05    1.70    1.05    1.15   \n",
       "\n",
       "                    Ticker                ExpiryDate   Strike Instrument Type  \n",
       "0  NIFTY03FEB2216050PE.NFO 2022-02-03 00:00:00+00:00  16050.0              PE  \n",
       "1  NIFTY06JAN2215500PE.NFO 2022-01-06 00:00:00+00:00  15500.0              PE  \n",
       "2  NIFTY13JAN2217750CE.NFO 2022-01-13 00:00:00+00:00  17750.0              CE  \n",
       "3  NIFTY06JAN2215100PE.NFO 2022-01-06 00:00:00+00:00  15100.0              PE  \n",
       "4  NIFTY06JAN2215150PE.NFO 2022-01-06 00:00:00+00:00  15150.0              PE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optionsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated get close price fucntion\n",
    "def get_close_price(strike_price, option_type, current_datetime, expiry_date):\n",
    "    try:\n",
    "        # First filter based on the first criteria\n",
    "        \n",
    "        # filtered_opd = optionsData.loc[(optionsData['Datetime'] == current_datetime) & (optionsData['Strike'] == strike_price) & (optionsData['ExpiryDate'] == expiry_date) & (optionsData['Instrument Type'] == option_type)]\n",
    "        \n",
    "        expiry_date = pd.to_datetime(expiry_date).date()\n",
    "        filtered_opd = optionsData[optionsData['Datetime'] == current_datetime]\n",
    "        filtered_opd = filtered_opd[filtered_opd['Instrument Type'] == option_type]\n",
    "        filtered_opd = filtered_opd[filtered_opd['Strike'] == strike_price]\n",
    "        filtered_opd['ExpiryDate'] = pd.to_datetime(filtered_opd['ExpiryDate']).dt.date\n",
    "        filtered_opd = filtered_opd[filtered_opd['ExpiryDate'] == expiry_date]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Now, apply the second criteria on the filtered DataFrame\n",
    "        result = filtered_opd['Close']\n",
    "\n",
    "        if result.empty:\n",
    "            logging.warning(f\"No close price found for {strike_price}, {option_type} at {current_datetime} for expiry {expiry_date}\")\n",
    "            return 0\n",
    "        else:\n",
    "            return result.values[0]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while fetching close price for {strike_price} at {current_datetime}\")\n",
    "        logging.error(e)\n",
    "\n",
    "\n",
    "\n",
    "# get close price dict\n",
    "def get_close_price_dict(atm_sp, wing_call, wing_put, current_datetime, expiry_date, i, df):\n",
    "    try:\n",
    "        # Define a list to store the futures\n",
    "        futures = []\n",
    "\n",
    "        # Create a ThreadPoolExecutor with a maximum of 4 threads\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            # Submit tasks to fetch close prices asynchronously\n",
    "            futures.append(executor.submit(get_close_price, atm_sp, 'CE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, atm_sp, 'PE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, wing_call, 'CE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, wing_put, 'PE', current_datetime, expiry_date))\n",
    "\n",
    "        # Retrieve the results\n",
    "        results = [future.result() for future in futures]\n",
    "        \n",
    "        try:\n",
    "            for j in range(len(results)):\n",
    "                if results[j] == False:\n",
    "                    previous_value = df.at[i - 1, f'legPriceOrignal{j + 1}']\n",
    "                    if np.isnan(previous_value):\n",
    "                        results[j] = 0\n",
    "                    else:\n",
    "                        results[j] = previous_value\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_close_price_dict: {e}\")\n",
    "\n",
    "        # Map the results to the ticker names\n",
    "        close_prices = {\n",
    "            'atmSPCall': results[0],\n",
    "            'atmSPPut': results[1],\n",
    "            'wingCallPrice': results[2],\n",
    "            'wingPutPrice': results[3]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        return close_prices, df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in get_close_price_dict: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions\n",
    "positions = {'beginx': [-1, -1, 1, 1], 'buy': [0, -2, 2, 2], 'sell': [-2, 0, 2, 2], 'squareoff': [0, 0, 0, 0], 'hard-squareoff': [0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check Stop Loss\n",
    "def check_stoploss(current_balance, capital_at_start_of_trade):\n",
    "    # Calculate the difference in capital from the start to the current balance\n",
    "    difference_in_capital = capital_at_start_of_trade - current_balance\n",
    "\n",
    "    # Check if the difference is more than 3% of the initial capital\n",
    "    return difference_in_capital > 0.03 * capital_at_start_of_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2m calculation\n",
    "num_legs = 4\n",
    "\n",
    "columns_to_reset = [ 'atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2',\n",
    "    'legPriceOrignal3', 'legPriceOrignal4', 'balance', 'lpos1', 'lpos2', 'lpos3',\n",
    "    'lpos4', 'legAfterPos1', 'legAfterPos2', 'legAfterPos3', 'legAfterPos4',\n",
    "    'legAfterPosDiff1', 'legAfterPosDiff2', 'legAfterPosDiff3', 'legAfterPosDiff4',\n",
    "    'legPriceFinal1', 'legPriceFinal2', 'legPriceFinal3', 'legPriceFinal4',\n",
    "    'm2m1', 'm2m2', 'm2m3', 'm2m4', 'totalPL', 'cumReturns'\n",
    "]\n",
    "\n",
    "lpos_column_names = [f\"lpos{i+1}\" for i in range(num_legs)]\n",
    "\n",
    "\n",
    "def calculate_m2m_new(index, start_day=False, caller='o'):\n",
    "    if str(df.at[index, 'position']).lower() == 'hold':\n",
    "        df.at[index, 'totalPL'] = 0\n",
    "        df.at[index, 'cumReturns'] = df.at[index-1, 'cumReturns']\n",
    "        df.at[index, 'balance'] = df.at[index-1, 'balance']\n",
    "        return\n",
    "    position_to_take = positions[str(df.at[index, 'position'])]\n",
    "    \n",
    "    \n",
    "    for i in range(0, num_legs):\n",
    "        df.at[index, f\"lpos{i+1}\"] = position_to_take[i]\n",
    "        # Calculating the leg after position\n",
    "        df.at[index, f\"legAfterPos{i+1}\"] = df.at[index, f\"legPriceOrignal{i+1}\"] * df.at[index, f\"lpos{i+1}\"]\n",
    "        \n",
    "\n",
    "        # Calculating the difference between the leg after position and the previous leg after position\n",
    "        difference_in_position = df.at[index, f\"lpos{i+1}\"] - df.at[index-1, f\"lpos{i+1}\"]\n",
    "        df.at[index, f\"legAfterPosDiff{i+1}\"] = difference_in_position * df.at[index, f\"legPriceOrignal{i+1}\"]\n",
    "\n",
    "        # Calculating Final Leg Price\n",
    "        df.at[index, f\"legPriceFinal{i+1}\"] = df.at[index, f\"legAfterPosDiff{i+1}\"] + df.at[index-1, f\"legAfterPos{i+1}\"]\n",
    "\n",
    "        if not start_day:\n",
    "            # Calculating m2m\n",
    "            df.at[index, f\"m2m{i+1}\"] = df.at[index, f\"legPriceFinal{i+1}\"] - df.at[index, f\"legAfterPos{i+1}\"]\n",
    "        else:\n",
    "            df.at[index, f\"m2m{i+1}\"] = 0\n",
    "\n",
    "        \n",
    "        # calculating the current data pnl which is the sum of all m2ms\n",
    "        df.at[index, 'totalPL'] += df.at[index, f\"m2m{i+1}\"]\n",
    "\n",
    "    # multiplying the totalPL by 50 for the lot size\n",
    "    df.at[index, 'totalPL'] = df.at[index, 'totalPL'] * -1 * 50\n",
    "    df.at[index, 'cumReturns'] = df.at[index-1, 'cumReturns'] + df.at[index, 'totalPL'] \n",
    "    # updating the balance\n",
    "    df.at[index, 'balance'] = df.at[index-1, 'balance'] + df.at[index, 'totalPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squareoff_columns_reset = ['balance', 'lpos1', 'lpos2', 'lpos3',\n",
    "    'lpos4', 'legAfterPos1', 'legAfterPos2', 'legAfterPos3', 'legAfterPos4',\n",
    "    'legAfterPosDiff1', 'legAfterPosDiff2', 'legAfterPosDiff3', 'legAfterPosDiff4',\n",
    "    'legPriceFinal1', 'legPriceFinal2', 'legPriceFinal3', 'legPriceFinal4',\n",
    "    'm2m1', 'm2m2', 'm2m3', 'm2m4', 'totalPL', 'cumReturns']\n",
    "    \n",
    "# round to nearest 50\n",
    "def round_to_nearest_50(number):\n",
    "    return round(number / 50) * 50\n",
    "    \n",
    "for i in range(1, len(df)):\n",
    "    df.at[df.index[i], 'atmSP'] = round_to_nearest_50(df.at[df.index[i], 'Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine if the current time is before the target time\n",
    "\n",
    "def is_before_target_time(current_datetime, target_time=\"15:10:00+05:30\"):\n",
    "    target_time = datetime.strptime(target_time, \"%H:%M:%S%z\")\n",
    "    # Compare the time parts\n",
    "    return current_datetime.time() < target_time.time()\n",
    "\n",
    "\n",
    "def get_daily_diff(current_datetime):\n",
    "    day_of_week = current_datetime.weekday()\n",
    "    # Define a dictionary to map each day to its corresponding difference\n",
    "    day_diff_mapping = {\n",
    "        \"Monday\": 400,\n",
    "        \"Tuesday\": 300,\n",
    "        \"Wednesday\": 200,\n",
    "        \"Thursday\": 100,\n",
    "        \"Friday\": 500,\n",
    "        \"Saturday\": 0,\n",
    "        \"Sunday\": 0\n",
    "    }\n",
    "    # Return the difference based on the day of the week\n",
    "    return day_diff_mapping[datetime.strftime(current_datetime, '%A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save data to csv\n",
    "def save_data():\n",
    "    df.to_csv(f'data/backtest/backtest{month}{year}-adaptiveSL-1min.csv')\n",
    "    # df.to_csv(f'/home/algolinux/7/D$/HirakDrive/workspace/GitHub/Endovia/data/backtest/backtest{year}-adaptiveSL.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logs.log', filemode='w', encoding='utf-8', level=logging.DEBUG, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in get_close_price_dict: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALGO1\\AppData\\Local\\Temp\\2\\ipykernel_14968\\3244970346.py:45: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '5.449999999999996' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'totalPL'] += df.at[index, f\"m2m{i+1}\"]\n",
      "C:\\Users\\ALGO1\\AppData\\Local\\Temp\\2\\ipykernel_14968\\3244970346.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-14.999999999999591' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'cumReturns'] = df.at[index-1, 'cumReturns'] + df.at[index, 'totalPL']\n",
      "C:\\Users\\ALGO1\\AppData\\Local\\Temp\\2\\ipykernel_14968\\3244970346.py:51: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '99987.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[index, 'balance'] = df.at[index-1, 'balance'] + df.at[index, 'totalPL']\n"
     ]
    }
   ],
   "source": [
    "position = \"squareoff\"\n",
    "\n",
    "# set the initial capital and the current capital hi hirak\n",
    "capital = 100000\n",
    "\n",
    "logging.info(\"*\"*100)\n",
    "\n",
    "first_run = True\n",
    "highest_m2m = 0\n",
    "\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    # timer_start = tm.time()\n",
    "    # Check if this a new day and time is 09:30:00+05:30\n",
    "\n",
    "    current_datetime_str = str(row.Datetime)[:-6]\n",
    "    current_datetime_str_short = current_datetime_str\n",
    "\n",
    "    has_traded_today = False\n",
    "    has_squareoff_today = False\n",
    "    logging.info(f\"Current Datetime: {current_datetime_str}\")\n",
    "\n",
    "    # check if the time is 09:30:00+05:30 or it is the first run\n",
    "    if '09:45:00' in current_datetime_str or first_run:\n",
    "        highest_m2m = 0\n",
    "        # Calculate the ATM strike price\n",
    "        atmSP = round_to_nearest_50(row.Close)\n",
    "        wingPut = atmSP - get_daily_diff(row.Datetime)\n",
    "        wingCall = atmSP + get_daily_diff(row.Datetime)\n",
    "        \n",
    "        # marking the postion as 0 updating tickers_dict\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "        if first_run:\n",
    "            # Reset values to 0 for the specified columns at row i\n",
    "            df.loc[i, columns_to_reset] = 0\n",
    "            df.at[i, 'position'] = 'hold'\n",
    "            position = 'hold'\n",
    "            df.at[i, 'balance'] = capital\n",
    "            first_run = False\n",
    "        else:\n",
    "            df.at[i, 'position'] = 'beginx'\n",
    "            position = 'hold'\n",
    "            calculate_m2m_new(i, start_day=True, caller='beginx 9:45')\n",
    "            df.at[i, 'stoploss'] = highest_m2m - (100000*0.03)\n",
    "        # sell atmSP call -> api call # sell atmSp put -> api call # buy wingPut -> api call # buy wingCall -> api call\n",
    "    \n",
    "    elif df.at[i-1, 'position'] == 'hard-squareoff' and row.Datetime.time() > time(9, 30):\n",
    "        # if previous was hard-squareoff then hust continue and forward the values\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "        df.at[i, 'position'] = position = 'hard-squareoff'\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        df.at[i, 'cumReturns'] = df.at[i-1, 'cumReturns']\n",
    "        df.at[i, 'totalPL'] = 0\n",
    "    \n",
    "    # if time is 15:15:00+05:30 then squareoff all positions\n",
    "    elif row.Datetime.time() == time(15, 15):\n",
    "        # buy atmSp call -> api call # buy atmSp put -> api call # sell wingPut -> api call # sell wingCall -> api call\n",
    "        capital = df.at[i-1, 'balance']\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        df.at[i, 'position'] = position = 'squareoff'\n",
    "        # store the values in the dataframe\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]         \n",
    "        calculate_m2m_new(i, caller='15:15')\n",
    "    \n",
    "    elif row.Datetime.time() > time(15, 15) and row.Datetime.time() <= time(15, 30):\n",
    "        # store the values in the dataframe\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut'] ] = [atmSP, wingCall, wingPut]\n",
    "        df.at[df.index[i], 'position'] = position =  'hold'\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "    \n",
    "    # between 9:15:00+05:30 and 9:29:00+05:30\n",
    "    elif row.Datetime.time() < time(9, 45) and row.Datetime.time() >= time(9, 15):\n",
    "        # df.loc[i, ['atmSP', 'wingCall', 'wingPut'] ] = [atmSP, wingCall, wingPut]\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut'] ] = [atmSP, wingCall, wingPut]\n",
    "        df.at[df.index[i], 'position'] = 'hold'\n",
    "        logging.debug(f\"balance at 9:15: {df.at[i-1, 'balance']}\")\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        position = 'hold'\n",
    "    \n",
    "    elif df.at[i-1, 'position'] == 'squareoff' and row.Datetime.time() > time(9, 30):\n",
    "\n",
    "        # check if current Datetime minutes is a 00, 15, 30, 45\n",
    "        if row.Datetime.minute % 15 == 0:\n",
    "            # Calculate the ATM strike price\n",
    "            atmSP = round_to_nearest_50(row.Close)\n",
    "            wingPut = atmSP - get_daily_diff(row.Datetime)\n",
    "            wingCall = atmSP + get_daily_diff(row.Datetime)\n",
    "            close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "            df.at[i, 'position'] = position = 'beginx'\n",
    "            df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "            calculate_m2m_new(i, start_day=True, caller='beginx')\n",
    "        else:\n",
    "            df.at[i, 'position'] = position = 'squareoff'\n",
    "            df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "            df.at[i, 'cumReturns'] = df.at[i-1, 'cumReturns']\n",
    "            df.at[i, 'totalPL'] = 0\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "        if position == 'hold':\n",
    "            if row.signal == 'Buy':\n",
    "                if row.rsi < 70 and row.ama < row.Close:\n",
    "                    # buy atmSp call -> api call # Sell atmSp put -> api call # buy wingCall -> api call # buy wingPut -> api call\n",
    "                    df.at[i, 'position'] = position = 'buy'\n",
    "                    has_traded_today = True\n",
    "            \n",
    "            elif row.signal == 'Sell':\n",
    "                if row.rsi > 30 and row.ama > row.Close:\n",
    "                    # sell atmSp call -> api call # buy atmSp put -> api call # Buy wingPut -> api call # Buy wingCall -> api call\n",
    "                    df.at[i, 'position'] = position = 'sell'\n",
    "                    has_traded_today = True\n",
    "\n",
    "        elif position == 'buy':\n",
    "            if row.signal == 'Hold':\n",
    "                if row.rsi > 70:\n",
    "                    # buy atmSp put -> api call x 2 # sell wingPut -> api call x 2 # sell wingCall -> api call x 2\n",
    "                    df.at[i, 'position'] = position = 'squareoff'\n",
    "                    has_traded_today = True\n",
    "            \n",
    "            elif row.signal == 'Sell':          \n",
    "                # buy atmSp put -> api call # sell wingPut -> api call # sell wingCall -> api call\n",
    "                df.at[i, 'position'] = position =  'squareoff'\n",
    "                has_traded_today = True\n",
    "\n",
    "        elif position == 'sell':\n",
    "            if row.signal == 'Hold':\n",
    "                if row.rsi < 30:              \n",
    "                    # buy atmSp call -> api call # sell wingPut -> api call # sell wingCall -> api call  \n",
    "                    df.at[i, 'position'] = position = 'squareoff'\n",
    "                    has_traded_today = True\n",
    "\n",
    "                    \n",
    "            elif row.signal == 'Buy':\n",
    "                df.at[df.index[i], 'position'] = position = 'squareoff'\n",
    "                has_traded_today = True\n",
    "                \n",
    "\n",
    "        df.at[i, 'position'] = position\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "\n",
    "\n",
    "        if not has_traded_today:\n",
    "            df.at[i, 'position'] = df.at[i-1, 'position']\n",
    "\n",
    "        \n",
    "        # called everytime\n",
    "        calculate_m2m_new(i, caller='daily')\n",
    "\n",
    "        if df.at[i, 'cumReturns'] > highest_m2m:\n",
    "            highest_m2m = df.at[i, 'cumReturns']\n",
    "        \n",
    "        df.at[i, 'stoploss'] = stoploss_price = highest_m2m - (100000*0.03)\n",
    "\n",
    "        if df.at[i, 'cumReturns'] < stoploss_price:\n",
    "            logging.info(f\" Stoploss hit at {current_datetime_str} with highest m2m: {highest_m2m} and stoploss price: {stoploss_price}\")\n",
    "            logging.info(f\" Stoploss hit at {current_datetime_str}\")\n",
    "            # squareoff all positions\n",
    "            df.loc[i, squareoff_columns_reset] = 0\n",
    "            df.at[i, 'position'] = position = 'hard-squareoff'\n",
    "            calculate_m2m_new(i, caller='hard-squareoff')\n",
    "            highest_m2m = df.at[i, 'cumReturns']\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    # timer_end = tm.time()\n",
    "    # logging.info(f\"Time taken for this iteration: {timer_end - timer_start} seconds\")\n",
    "\n",
    "\n",
    "    # df.at[df.index[i], 'position'] = position\n",
    "\n",
    "\n",
    "save_data()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
