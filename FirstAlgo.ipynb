{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from datetime import datetime, timezone, timedelta, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import csv\n",
    "import time as tm\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import timeit\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Spot Data\n",
    "df = pd.read_csv('data/2023/NiftySpotData-withSignal-with-closestExpiry-15min-2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 1 min candle to 15 min candle\n",
    "\n",
    "# Convert 'Datetime' column to datetime type if it's not already\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "# Determine the start time of the first interval\n",
    "start_time_first_interval = df['Datetime'].iloc[0].replace(hour=9, minute=30, second=0, microsecond=0)\n",
    "\n",
    "# Calculate the number of 15-minute intervals from the market opening time (9:30 AM)\n",
    "df['Interval'] = ((df['Datetime'] - start_time_first_interval) // timedelta(minutes=15)).astype(int)\n",
    "\n",
    "# Group by the new 'Interval' column and aggregate open, high, low, close values\n",
    "result_df = df.groupby('Interval').agg({\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Open': 'first',\n",
    "    'Close': 'last'\n",
    "})\n",
    "\n",
    "# Reset the index\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "# Calculate the datetime using the start time of the first interval\n",
    "result_df['Datetime'] = start_time_first_interval + result_df['Interval'] * timedelta(minutes=15)\n",
    "\n",
    "# Drop the 'Interval' column if you don't need it in the final result\n",
    "result_df.drop(columns='Interval', inplace=True)\n",
    "\n",
    "result_df['Datetime'] = pd.to_datetime(result_df['Datetime'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "df = result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ADM (adapting moving average)\n",
    "def adaptive_moving_average(close_prices, window=14, fast_factor=2.0, slow_factor=30.0):\n",
    "    volatility = close_prices.pct_change().rolling(window=window, min_periods=window).std()\n",
    "    fast_ema = close_prices.ewm(span=fast_factor * window, adjust=False).mean()\n",
    "    slow_ema = close_prices.ewm(span=slow_factor * window, adjust=False).mean()\n",
    "    ama = (fast_ema + volatility * (close_prices - slow_ema)).ewm(span=window, adjust=False).mean()\n",
    "    return ama\n",
    "\n",
    "df['ama'] = adaptive_moving_average(df['Close'], window=14, fast_factor=2, slow_factor=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the RSI\n",
    "df['rsi'] = talib.RSI(df['Close'], timeperiod=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ATR\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "np.set_printoptions(suppress=True,linewidth=np.nan)\n",
    "pd.options.display.float_format = '{:,.4f}'.format\n",
    "\n",
    "\n",
    "def calculate_atr(data, period=14):\n",
    "    # Calculate True Range (TR)\n",
    "    data['high-low'] = data['High'] - data['Low']\n",
    "    data['high-close_prev'] = abs(data['High'] - data['Close'].shift(1))\n",
    "    data['low-close_prev'] = abs(data['Low'] - data['Close'].shift(1))\n",
    "    data['true_range'] = data[['high-low', 'high-close_prev', 'low-close_prev']].max(axis=1)\n",
    "\n",
    "    # Calculate ATR\n",
    "    data['atr'] = data['true_range'].rolling(window=period, min_periods=1).mean()\n",
    "\n",
    "    # Drop intermediate columns\n",
    "    data.drop(['high-low', 'high-close_prev', 'low-close_prev', 'true_range'], axis=1, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "df = calculate_atr(df, period=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Pivot Points\n",
    "def calculate_pivot_points(data, column_name, length=14):\n",
    "    if column_name == 'High':\n",
    "        pivot_points = pd.DataFrame(index=data.index, columns=[column_name, f'IsPivot{column_name.capitalize()}'])\n",
    "\n",
    "        for i in range(length, len(data) - length):\n",
    "            # Check if the current point is a pivot high\n",
    "            is_pivot_point = all(data[column_name][i] > data[column_name][i - length:i]) and all(data[column_name][i] > data[column_name][i + 1:i + length + 1])\n",
    "            # is_pivot_point = all(data[column_name][i] > data[column_name][i - length:i]) \n",
    "\n",
    "            # Store the values in the DataFrame\n",
    "            pivot_points.at[data.index[i], column_name] = data[column_name][i] if is_pivot_point else None\n",
    "\n",
    "            pivot_points.at[data.index[i], f'IsPivot{column_name.capitalize()}'] = is_pivot_point\n",
    "    \n",
    "    elif column_name == 'Low':\n",
    "        pivot_points = pd.DataFrame(index=data.index, columns=[column_name, f'IsPivot{column_name.capitalize()}'])\n",
    "        for i in range(length, len(data) - length):\n",
    "            # Check if the current point is a pivot low\n",
    "            is_pivot_point = all(data[column_name][i] < data[column_name][i - length:i]) and all(data[column_name][i] < data[column_name][i + 1:i + length + 1])\n",
    "            # is_pivot_point = all(data[column_name][i] < data[column_name][i - length:i])\n",
    "\n",
    "            # Store the values in the DataFrame\n",
    "            pivot_points.at[data.index[i], column_name] = data[column_name][i] if is_pivot_point else None\n",
    "\n",
    "            pivot_points.at[data.index[i], f'IsPivot{column_name.capitalize()}'] = is_pivot_point\n",
    "\n",
    "    return pivot_points\n",
    "\n",
    "\n",
    "PH = calculate_pivot_points(df, 'High', length=14)\n",
    "df['PL'] = calculate_pivot_points(df, 'Low', length=14)['IsPivotLow']\n",
    "\n",
    "df['PH'] = PH['IsPivotHigh'] \n",
    "\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PH']:\n",
    "        df.at[df.index[i], 'PH_val'] = df.at[df.index[i], 'High']\n",
    "    else:\n",
    "        df.at[df.index[i], 'PH_val'] = df.at[df.index[i - 1], 'PH_val']\n",
    "    if df.at[df.index[i], 'PL']:\n",
    "        df.at[df.index[i], 'PL_val'] = df.at[df.index[i], 'Low']\n",
    "    else:\n",
    "        df.at[df.index[i], 'PL_val'] = df.at[df.index[i - 1], 'PL_val']\n",
    "\n",
    "df['Slope'] = df['atr']/14\n",
    "\n",
    "# Initialize the first values for slope_ph and slope_pl\n",
    "df.at[df.index[0], 'slope_ph'] = df.at[df.index[0], 'Slope']\n",
    "df.at[df.index[0], 'slope_pl'] = df.at[df.index[0], 'Slope']\n",
    "\n",
    "\n",
    "# Update slope_ph and slope_pl based on conditions\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PH']:\n",
    "        df.at[df.index[i], 'slope_ph'] = df.at[df.index[i], 'Slope']\n",
    "    else:\n",
    "        df.at[df.index[i], 'slope_ph'] = df.at[df.index[i - 1], 'slope_ph']\n",
    "    if df.at[df.index[i], 'PL']:\n",
    "        df.at[df.index[i], 'slope_pl'] = df.at[df.index[i], 'Slope']\n",
    "    else:\n",
    "        df.at[df.index[i], 'slope_pl'] = df.at[df.index[i - 1], 'slope_pl']\n",
    "\n",
    "\n",
    "\n",
    "df['upper'] = 0\n",
    "df['lower'] = 0\n",
    "# Update upper and lower based on conditions\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PH'] == True:\n",
    "        df.at[df.index[i], 'upper'] = df.at[df.index[i], 'High']\n",
    "    else:\n",
    "        df.at[df.index[i], 'upper'] = df.at[df.index[i - 1], 'upper'] - df.at[df.index[i], 'slope_ph']\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PL'] == True:\n",
    "        df.at[df.index[i], 'lower'] = df.at[df.index[i], 'Low']\n",
    "    else:\n",
    "        df.at[df.index[i], 'lower'] = df.at[df.index[i - 1], 'lower'] + df.at[df.index[i], 'slope_pl']\n",
    "        \n",
    "\n",
    "# length = 14\n",
    "df['upos'] = 0\n",
    "df['dnos'] = 0\n",
    "\n",
    "# Calculate upos\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PH'] != True or df.at[df.index[i], 'PL'] =='':\n",
    "        upper_limit = df.at[df.index[i - 1], 'upper']\n",
    "        if df.at[df.index[i], 'Close'] > upper_limit:\n",
    "            df.at[df.index[i], 'upos'] = 1\n",
    "\n",
    "# Calculate dnos\n",
    "for i in range(1, len(df)):\n",
    "    if df.at[df.index[i], 'PL'] != True or df.at[df.index[i], 'PH'] == '':\n",
    "        lower_limit = df.at[df.index[i - 1], 'lower']\n",
    "        if df.at[df.index[i], 'Close'] < lower_limit:\n",
    "            df.at[df.index[i], 'dnos'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calulating the pivot highs and pivot lows\n",
    "pivot = calculate_pivot_points(df, 'High', length=14)\n",
    "df['IsPivotHigh'] = pivot['IsPivotHigh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the signals\n",
    "\n",
    "df['signal'] = 'Hold'\n",
    "\n",
    "buy_condition = (df['upos'] > df['upos'].shift(1)) & (df['signal'] != 'Buy')\n",
    "sell_condition = (df['dnos'] > df['dnos'].shift(1)) & (df['signal'] != 'Sell')\n",
    "\n",
    "df.loc[buy_condition, 'signal'] = 'Buy'\n",
    "df.loc[sell_condition, 'signal'] = 'Sell'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data SPOT to a csv file\n",
    "df.to_csv('data/2023/NiftySpotData-withSignal-with-closestExpiry-15min-2023.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formating code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert closest_expiry to %D%B%Y format in all upper case\n",
    "df['dby'] = df['closest_expiry'].dt.strftime('%d%b%y').str.upper()\n",
    "\n",
    "# keep values that are in between 9:15 to 15:15 including them\n",
    "df = df[(df['Datetime'].dt.time >= time(9, 15)) & (df['Datetime'].dt.time <= time(15, 15))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('NiftySpotData1-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from datetime import datetime, timezone, timedelta, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import csv\n",
    "import time as tm\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import timeit\n",
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/2024/NiftySpotData-2024-15min-Signal-Expiry.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/NiftySpotData-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myear\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-15min-Signal-Expiry.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m year \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2024\u001b[39m:\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32md:\\HirakDrive\\workspace\\GitHub\\Endovia\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/2024/NiftySpotData-2024-15min-Signal-Expiry.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f'data/{year}/NiftySpotData-{year}-15min-Signal-Expiry.csv')\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "if year == 2024:\n",
    "    df['closest_expiry'] = pd.to_datetime(df['closest_expiry'], format='%Y-%m-%d')\n",
    "    # convert to %Y-%m-%d %H:%M:%S%z format\n",
    "    df['closest_expiry'] = df['closest_expiry'].dt.strftime('%Y-%m-%d %H:%M:%S%z')\n",
    "else:\n",
    "    df['closest_expiry'] = pd.to_datetime(df['closest_expiry'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "try:\n",
    "    # df drop PL PH, PL_val, PH_val, slope_ph, slope_pl, upper, lower, upos, dnos, IsPivotHigh\n",
    "    df.drop(['PL', 'PH', 'PL_val', 'PH_val', 'slope_ph', 'slope_pl', 'upper', 'lower', 'upos', 'dnos', 'IsPivotHigh', 'Slope'], axis=1, inplace=True)\n",
    "    df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize all columns with NaN\n",
    "df = df.assign(\n",
    "    position='', atmSP=np.nan, wingCall=np.nan, wingPut=np.nan, legPriceOrignal1=np.nan, legPriceOrignal2=np.nan,\n",
    "    legPriceOrignal3=np.nan, legPriceOrignal4=np.nan, lpos1=np.nan, lpos2=np.nan, lpos3=np.nan, lpos4=np.nan,\n",
    "    legAfterPos1=np.nan, legAfterPos2=np.nan, legAfterPos3=np.nan, legAfterPos4=np.nan, legAfterPosDiff1=np.nan,\n",
    "    legAfterPosDiff2=np.nan, legAfterPosDiff3=np.nan, legAfterPosDiff4=np.nan, legPriceFinal1=np.nan,\n",
    "    legPriceFinal2=np.nan, legPriceFinal3=np.nan, legPriceFinal4=np.nan, m2m1=np.nan, m2m2=np.nan, m2m3=np.nan,\n",
    "    m2m4=np.nan, totalPL=0, cumReturns=0, balance=0\n",
    ")\n",
    "\n",
    "# only keep values between 9:15 to 15:30\n",
    "df = df[(df['Datetime'].dt.time >= time(9, 15)) & (df['Datetime'].dt.time <= time(15, 30))]\n",
    "\n",
    "# reset df index\n",
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dates_to_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# account for missing optionsData by dropping the rows from df where Datetime is\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dates_to_drop = ['2023-02-16', '2023-03-07', '2023-03-30', '2023-04-04', '2023-09-19', '2023-04-25', '2023-01-20', '2023-10-22', '2023-10-24']\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# dates_to_drop = ['2022-09-22']\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# dates_to_drop = ['2021-01-08', '2021-02-24', '2021-07-16', '2021-08-02', '2021-11-03', '2021-11-04']\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# dates_to_drop = ['2020-01-31', '2020-03-13']\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# dates_to_drop = ['2024-03-02']\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdates_to_drop\u001b[49m:\n\u001b[1;32m      8\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate \u001b[38;5;241m!=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date)\u001b[38;5;241m.\u001b[39mdate()]\n\u001b[1;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dates_to_drop' is not defined"
     ]
    }
   ],
   "source": [
    "# account for missing optionsData by dropping the rows from df where Datetime is\n",
    "# dates_to_drop = ['2023-02-16', '2023-03-07', '2023-03-30', '2023-04-04', '2023-09-19', '2023-04-25', '2023-01-20', '2023-10-22', '2023-10-24']\n",
    "# dates_to_drop = ['2022-09-22']\n",
    "# dates_to_drop = ['2021-01-08', '2021-02-24', '2021-07-16', '2021-08-02', '2021-11-03', '2021-11-04']\n",
    "# dates_to_drop = ['2020-01-31', '2020-03-13']\n",
    "dates_to_drop = ['2024-03-02']\n",
    "for date in dates_to_drop:\n",
    "    df = df[df['Datetime'].dt.date != pd.to_datetime(date).date()]\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>ama</th>\n",
       "      <th>rsi</th>\n",
       "      <th>atr</th>\n",
       "      <th>signal</th>\n",
       "      <th>closest_expiry</th>\n",
       "      <th>...</th>\n",
       "      <th>legPriceFinal2</th>\n",
       "      <th>legPriceFinal3</th>\n",
       "      <th>legPriceFinal4</th>\n",
       "      <th>m2m1</th>\n",
       "      <th>m2m2</th>\n",
       "      <th>m2m3</th>\n",
       "      <th>m2m4</th>\n",
       "      <th>totalPL</th>\n",
       "      <th>cumReturns</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22668.40</td>\n",
       "      <td>22618.45</td>\n",
       "      <td>22627.65</td>\n",
       "      <td>22646.50</td>\n",
       "      <td>2024-05-02 09:15:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.150000</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2024-05-02 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22674.35</td>\n",
       "      <td>22617.70</td>\n",
       "      <td>22646.25</td>\n",
       "      <td>22642.45</td>\n",
       "      <td>2024-05-02 09:30:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.983333</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2024-05-02 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22680.35</td>\n",
       "      <td>22634.25</td>\n",
       "      <td>22640.90</td>\n",
       "      <td>22669.50</td>\n",
       "      <td>2024-05-02 09:45:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.762500</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2024-05-02 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22677.45</td>\n",
       "      <td>22655.95</td>\n",
       "      <td>22669.00</td>\n",
       "      <td>22677.45</td>\n",
       "      <td>2024-05-02 10:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.710000</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2024-05-02 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22693.75</td>\n",
       "      <td>22669.60</td>\n",
       "      <td>22677.15</td>\n",
       "      <td>22684.15</td>\n",
       "      <td>2024-05-02 10:15:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.783333</td>\n",
       "      <td>Hold</td>\n",
       "      <td>2024-05-02 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       High       Low      Open     Close                  Datetime  ama  rsi  \\\n",
       "0  22668.40  22618.45  22627.65  22646.50 2024-05-02 09:15:00+00:00  NaN  NaN   \n",
       "1  22674.35  22617.70  22646.25  22642.45 2024-05-02 09:30:00+00:00  NaN  NaN   \n",
       "2  22680.35  22634.25  22640.90  22669.50 2024-05-02 09:45:00+00:00  NaN  NaN   \n",
       "3  22677.45  22655.95  22669.00  22677.45 2024-05-02 10:00:00+00:00  NaN  NaN   \n",
       "4  22693.75  22669.60  22677.15  22684.15 2024-05-02 10:15:00+00:00  NaN  NaN   \n",
       "\n",
       "         atr signal       closest_expiry  ... legPriceFinal2 legPriceFinal3  \\\n",
       "0  72.150000   Hold  2024-05-02 00:00:00  ...            NaN            NaN   \n",
       "1  66.983333   Hold  2024-05-02 00:00:00  ...            NaN            NaN   \n",
       "2  61.762500    Buy  2024-05-02 00:00:00  ...            NaN            NaN   \n",
       "3  53.710000   Hold  2024-05-02 00:00:00  ...            NaN            NaN   \n",
       "4  48.783333   Hold  2024-05-02 00:00:00  ...            NaN            NaN   \n",
       "\n",
       "   legPriceFinal4  m2m1  m2m2  m2m3  m2m4  totalPL  cumReturns  balance  \n",
       "0             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "1             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "2             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "3             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "4             NaN   NaN   NaN   NaN   NaN        0           0        0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the options data\n",
    "optionsData = pd.read_csv(f'data/{year}/NiftyOptionsData-{year}-15min.csv')\n",
    "\n",
    "# optionsData.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# Convert the 'Datetime' column to datetime format\n",
    "optionsData['Datetime'] = pd.to_datetime(optionsData['Datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "optionsData['ExpiryDate'] = pd.to_datetime(optionsData['ExpiryDate'], format='%Y-%m-%d %H:%M:%S%z')\n",
    "\n",
    "\n",
    "# # keep only data where time is ending in 00, 15, 30, 45 mins\n",
    "optionsData = optionsData[optionsData['Datetime'].dt.minute % 15 == 0]\n",
    "\n",
    "optionsData = optionsData.sort_values(by='Datetime')\n",
    "optionsData.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>ExpiryDate</th>\n",
       "      <th>Strike</th>\n",
       "      <th>Instrument Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 09:15:00</td>\n",
       "      <td>366.00</td>\n",
       "      <td>366.00</td>\n",
       "      <td>366.00</td>\n",
       "      <td>366.00</td>\n",
       "      <td>NIFTY24MAR21500PE.NFO</td>\n",
       "      <td>2024-03-28 00:00:00+00:00</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 09:15:00</td>\n",
       "      <td>626.50</td>\n",
       "      <td>626.50</td>\n",
       "      <td>626.50</td>\n",
       "      <td>626.50</td>\n",
       "      <td>NIFTY24JAN21350CE.NFO</td>\n",
       "      <td>2024-01-25 00:00:00+00:00</td>\n",
       "      <td>21350.0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 09:15:00</td>\n",
       "      <td>141.15</td>\n",
       "      <td>141.15</td>\n",
       "      <td>141.15</td>\n",
       "      <td>141.15</td>\n",
       "      <td>NIFTY24MAR20350PE.NFO</td>\n",
       "      <td>2024-03-28 00:00:00+00:00</td>\n",
       "      <td>20350.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 09:15:00</td>\n",
       "      <td>683.95</td>\n",
       "      <td>683.95</td>\n",
       "      <td>665.00</td>\n",
       "      <td>665.00</td>\n",
       "      <td>NIFTY24JAN21300CE.NFO</td>\n",
       "      <td>2024-01-25 00:00:00+00:00</td>\n",
       "      <td>21300.0</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 09:15:00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NIFTY2410420900PE.NFO</td>\n",
       "      <td>2024-01-04 00:00:00+00:00</td>\n",
       "      <td>20900.0</td>\n",
       "      <td>PE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime    Open    High     Low   Close                 Ticker  \\\n",
       "0 2024-01-01 09:15:00  366.00  366.00  366.00  366.00  NIFTY24MAR21500PE.NFO   \n",
       "1 2024-01-01 09:15:00  626.50  626.50  626.50  626.50  NIFTY24JAN21350CE.NFO   \n",
       "2 2024-01-01 09:15:00  141.15  141.15  141.15  141.15  NIFTY24MAR20350PE.NFO   \n",
       "3 2024-01-01 09:15:00  683.95  683.95  665.00  665.00  NIFTY24JAN21300CE.NFO   \n",
       "4 2024-01-01 09:15:00    4.00    4.95    2.55    3.50  NIFTY2410420900PE.NFO   \n",
       "\n",
       "                 ExpiryDate   Strike Instrument Type  \n",
       "0 2024-03-28 00:00:00+00:00  21500.0              PE  \n",
       "1 2024-01-25 00:00:00+00:00  21350.0              CE  \n",
       "2 2024-03-28 00:00:00+00:00  20350.0              PE  \n",
       "3 2024-01-25 00:00:00+00:00  21300.0              CE  \n",
       "4 2024-01-04 00:00:00+00:00  20900.0              PE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optionsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated get close price fucntion\n",
    "def get_close_price(strike_price, option_type, current_datetime, expiry_date):\n",
    "    try:\n",
    "        # First filter based on the first criteria\n",
    "        \n",
    "        # filtered_opd = optionsData.loc[(optionsData['Datetime'] == current_datetime) & (optionsData['Strike'] == strike_price) & (optionsData['ExpiryDate'] == expiry_date) & (optionsData['Instrument Type'] == option_type)]\n",
    "            \n",
    "        filtered_opd = optionsData[optionsData['Datetime'] == current_datetime]\n",
    "        filtered_opd = filtered_opd[filtered_opd['Instrument Type'] == option_type]\n",
    "        filtered_opd = filtered_opd[filtered_opd['Strike'] == strike_price]\n",
    "        filtered_opd = filtered_opd[filtered_opd['ExpiryDate'] == expiry_date]\n",
    "        \n",
    "        \n",
    "\n",
    "        # Now, apply the second criteria on the filtered DataFrame\n",
    "        result = filtered_opd['Close']\n",
    "\n",
    "        if result.empty:\n",
    "            logging.warning(f\"No close price found for {strike_price}, {option_type} at {current_datetime} for expiry {expiry_date}\")\n",
    "            return False\n",
    "        else:\n",
    "            return result.values[0]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error while fetching close price for {strike_price} at {current_datetime}\")\n",
    "        logging.error(e)\n",
    "\n",
    "\n",
    "\n",
    "# get close price dict\n",
    "def get_close_price_dict(atm_sp, wing_call, wing_put, current_datetime, expiry_date, i, df):\n",
    "    try:\n",
    "        # Define a list to store the futures\n",
    "        futures = []\n",
    "\n",
    "        # Create a ThreadPoolExecutor with a maximum of 4 threads\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "            # Submit tasks to fetch close prices asynchronously\n",
    "            futures.append(executor.submit(get_close_price, atm_sp, 'CE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, atm_sp, 'PE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, wing_call, 'CE', current_datetime, expiry_date))\n",
    "            futures.append(executor.submit(get_close_price, wing_put, 'PE', current_datetime, expiry_date))\n",
    "\n",
    "        # Retrieve the results\n",
    "        results = [future.result() for future in futures]\n",
    "        \n",
    "        try:\n",
    "            for j in range(len(results)):\n",
    "                if results[j] == False:\n",
    "                    previous_value = df.at[i - 1, f'legPriceOrignal{j + 1}']\n",
    "                    if np.isnan(previous_value):\n",
    "                        results[j] = 0\n",
    "                    else:\n",
    "                        results[j] = previous_value\n",
    "        except Exception as e:\n",
    "            print(f\"Error in get_close_price_dict: {e}\")\n",
    "\n",
    "        # Map the results to the ticker names\n",
    "        close_prices = {\n",
    "            'atmSPCall': results[0],\n",
    "            'atmSPPut': results[1],\n",
    "            'wingCallPrice': results[2],\n",
    "            'wingPutPrice': results[3]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        return close_prices, df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in get_close_price_dict: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions\n",
    "positions = {'beginx': [-1, -1, 1, 1], 'buy': [0, -2, 2, 2], 'sell': [-2, 0, 2, 2], 'squareoff': [0, 0, 0, 0], 'hold': [0, 0, 0, 0], 'hard-squareoff': [0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check Stop Loss\n",
    "def check_stoploss(current_balance, capital_at_start_of_trade):\n",
    "    # Calculate the difference in capital from the start to the current balance\n",
    "    difference_in_capital = capital_at_start_of_trade - current_balance\n",
    "\n",
    "    # Check if the difference is more than 3% of the initial capital\n",
    "    return difference_in_capital > 0.03 * capital_at_start_of_trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2m calculation\n",
    "num_legs = 4\n",
    "\n",
    "columns_to_reset = [ 'atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2',\n",
    "    'legPriceOrignal3', 'legPriceOrignal4', 'balance', 'lpos1', 'lpos2', 'lpos3',\n",
    "    'lpos4', 'legAfterPos1', 'legAfterPos2', 'legAfterPos3', 'legAfterPos4',\n",
    "    'legAfterPosDiff1', 'legAfterPosDiff2', 'legAfterPosDiff3', 'legAfterPosDiff4',\n",
    "    'legPriceFinal1', 'legPriceFinal2', 'legPriceFinal3', 'legPriceFinal4',\n",
    "    'm2m1', 'm2m2', 'm2m3', 'm2m4', 'totalPL', 'cumReturns'\n",
    "]\n",
    "\n",
    "lpos_column_names = [f\"lpos{i+1}\" for i in range(num_legs)]\n",
    "\n",
    "\n",
    "def calculate_m2m_new(index, start_day=False, caller='o'):\n",
    "    position_to_take = positions[str(df.at[index, 'position'])]\n",
    "    \n",
    "    for i in range(0, num_legs):\n",
    "        df.at[index, f\"lpos{i+1}\"] = position_to_take[i]\n",
    "        # Calculating the leg after position\n",
    "        df.at[index, f\"legAfterPos{i+1}\"] = df.at[index, f\"legPriceOrignal{i+1}\"] * df.at[index, f\"lpos{i+1}\"]\n",
    "        \n",
    "\n",
    "        # Calculating the difference between the leg after position and the previous leg after position\n",
    "        difference_in_position = df.at[index, f\"lpos{i+1}\"] - df.at[index-1, f\"lpos{i+1}\"]\n",
    "        df.at[index, f\"legAfterPosDiff{i+1}\"] = difference_in_position * df.at[index, f\"legPriceOrignal{i+1}\"]\n",
    "\n",
    "        # Calculating Final Leg Price\n",
    "        df.at[index, f\"legPriceFinal{i+1}\"] = df.at[index, f\"legAfterPosDiff{i+1}\"] + df.at[index-1, f\"legAfterPos{i+1}\"]\n",
    "\n",
    "        if not start_day:\n",
    "            # Calculating m2m\n",
    "            df.at[index, f\"m2m{i+1}\"] = df.at[index, f\"legPriceFinal{i+1}\"] - df.at[index, f\"legAfterPos{i+1}\"]\n",
    "        else:\n",
    "            df.at[index, f\"m2m{i+1}\"] = 0\n",
    "\n",
    "        \n",
    "        # calculating the current data pnl which is the sum of all m2ms\n",
    "        df.at[index, 'totalPL'] += df.at[index, f\"m2m{i+1}\"]\n",
    "\n",
    "    # multiplying the totalPL by 50 for the lot size\n",
    "    df.at[index, 'totalPL'] = df.at[index, 'totalPL'] * -1 * 50\n",
    "    df.at[index, 'cumReturns'] = df.at[index-1, 'cumReturns'] + df.at[index, 'totalPL'] \n",
    "    # updating the balance\n",
    "    df.at[index, 'balance'] = df.at[index-1, 'balance'] + df.at[index, 'totalPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "squareoff_columns_reset = ['balance', 'lpos1', 'lpos2', 'lpos3',\n",
    "    'lpos4', 'legAfterPos1', 'legAfterPos2', 'legAfterPos3', 'legAfterPos4',\n",
    "    'legAfterPosDiff1', 'legAfterPosDiff2', 'legAfterPosDiff3', 'legAfterPosDiff4',\n",
    "    'legPriceFinal1', 'legPriceFinal2', 'legPriceFinal3', 'legPriceFinal4',\n",
    "    'm2m1', 'm2m2', 'm2m3', 'm2m4', 'totalPL', 'cumReturns']\n",
    " \n",
    "# round to nearest 50\n",
    "def round_to_nearest_50(number):\n",
    "    return round(number / 50) * 50\n",
    "    \n",
    "for i in range(1, len(df)):\n",
    "    df.at[df.index[i], 'atmSP'] = round_to_nearest_50(df.at[df.index[i], 'Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine if the current time is before the target time\n",
    "\n",
    "def is_before_target_time(current_datetime, target_time=\"15:10:00+05:30\"):\n",
    "    target_time = datetime.strptime(target_time, \"%H:%M:%S%z\")\n",
    "    # Compare the time parts\n",
    "    return current_datetime.time() < target_time.time()\n",
    "\n",
    "\n",
    "def get_daily_diff(current_datetime):\n",
    "    day_of_week = current_datetime.weekday()\n",
    "    # Define a dictionary to map each day to its corresponding difference\n",
    "    day_diff_mapping = {\n",
    "        \"Monday\": 400,\n",
    "        \"Tuesday\": 300,\n",
    "        \"Wednesday\": 200,\n",
    "        \"Thursday\": 100,\n",
    "        \"Friday\": 500,\n",
    "        \"Saturday\": 0,\n",
    "        \"Sunday\": 0\n",
    "    }\n",
    "    # Return the difference based on the day of the week\n",
    "    return day_diff_mapping[datetime.strftime(current_datetime, '%A')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save data to csv\n",
    "def save_data():\n",
    "    df.to_csv(f'data/backtest/final/backtest{year}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='logs.log', filemode='w', encoding='utf-8', level=logging.DEBUG, force=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in get_close_price_dict: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fv/h8flhzz90ljgbvrrq5wxfv4w0000gn/T/ipykernel_12886/968494099.py:34: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n"
     ]
    }
   ],
   "source": [
    "position = \"squareoff\"\n",
    "\n",
    "# set the initial capital and the current capital\n",
    "capital = 100000\n",
    "\n",
    "logging.info(\"*\"*100)\n",
    "\n",
    "highest_m2m = 0\n",
    "\n",
    "first_run = True\n",
    "\n",
    "for i, row in enumerate(df.itertuples()):\n",
    "    # timer_start = tm.time()\n",
    "    # Check if this a new day and time is 09:30:00+05:30\n",
    "\n",
    "    current_datetime_str = str(row.Datetime)[:-6]\n",
    "    current_datetime_str_short = current_datetime_str\n",
    "\n",
    "    has_traded_today = False\n",
    "    has_squareoff_today = False\n",
    "    logging.info(f\"Current Datetime: {current_datetime_str}\")\n",
    "\n",
    "    # check if the time is 09:30:00+05:30 or it is the first run\n",
    "    if '09:45:00' in current_datetime_str or first_run:\n",
    "        highest_m2m = 0\n",
    "        # Calculate the ATM strike price\n",
    "        atmSP = round_to_nearest_50(row.Close)\n",
    "        wingPut = atmSP - get_daily_diff(row.Datetime)\n",
    "        wingCall = atmSP + get_daily_diff(row.Datetime)\n",
    "        \n",
    "        # marking the postion as 0 updating tickers_dict\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "        if first_run:\n",
    "            # Reset values to 0 for the specified columns at row i\n",
    "            df.loc[i, columns_to_reset] = 0\n",
    "            df.at[i, 'position'] = 'hold'\n",
    "            position = 'hold'\n",
    "            df.at[i, 'balance'] = capital\n",
    "            first_run = False\n",
    "        else:\n",
    "            df.at[i, 'position'] = 'beginx'\n",
    "            position = 'hold'\n",
    "            calculate_m2m_new(i, start_day=True, caller='beginx 9:30')\n",
    "            df.at[i, 'stoploss'] = highest_m2m - (100000*0.03)\n",
    "        # sell atmSP call -> api call # sell atmSp put -> api call # buy wingPut -> api call # buy wingCall -> api call\n",
    "    \n",
    "    elif df.at[i-1, 'position'] == 'hard-squareoff' and row.Datetime.time() > time(9, 30):\n",
    "        # if previous was hard-squareoff then hust continue and forward the values\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "        df.at[i, 'position'] = position = 'hard-squareoff'\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        df.at[i, 'cumReturns'] = df.at[i-1, 'cumReturns']\n",
    "        df.at[i, 'totalPL'] = 0\n",
    "\n",
    "        \n",
    "    \n",
    "    # if time is 15:15:00+05:30 then squareoff all positions\n",
    "    elif row.Datetime.time() == time(15, 15):\n",
    "        # buy atmSp call -> api call # buy atmSp put -> api call # sell wingPut -> api call # sell wingCall -> api call\n",
    "        capital = df.at[i-1, 'balance']\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        df.at[i, 'position'] = position = 'squareoff'\n",
    "        # store the values in the dataframe\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)  \n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]         \n",
    "        rolling_dict = calculate_m2m_new(i, caller='15:15')\n",
    "    \n",
    "    elif row.Datetime.time() == time(15, 30):\n",
    "        # store the values in the dataframe\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut'] ] = [atmSP, wingCall, wingPut]\n",
    "        df.at[df.index[i], 'position'] = 'hold'\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "\n",
    "        position = 'hold'\n",
    "        \n",
    "    elif row.Datetime.time() >= time(9, 15) and row.Datetime.time() < time(9, 45):\n",
    "        # this is for time between 15:15:00+05:30 and 09:30:00+05:30\n",
    "        # store the values in the dataframe\n",
    "\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut'] ] = [atmSP, wingCall, wingPut]\n",
    "        df.at[df.index[i], 'position'] = 'hold'\n",
    "        logging.debug(f\"balance at 9:15: {df.at[i-1, 'balance']}\")\n",
    "        df.at[i, 'balance'] = df.at[i-1, 'balance']\n",
    "        position = 'hold'\n",
    "    \n",
    "    elif df.at[i-1, 'position'] == 'squareoff' and row.Datetime.time() > time(9, 30):\n",
    "        # if previous was squareoff then take position this time\n",
    "        logging.info(f\"Taking position at {current_datetime_str} by the elif block\")\n",
    "        atmSP = round_to_nearest_50(row.Close)\n",
    "        wingPut = atmSP - get_daily_diff(row.Datetime)\n",
    "        wingCall = atmSP + get_daily_diff(row.Datetime)\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df)  \n",
    "        df.at[i, 'position'] = position = 'beginx'\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "        calculate_m2m_new(i, start_day=True, caller='beginx')\n",
    "\n",
    "    \n",
    "    else:\n",
    "        close_price_dict, df = get_close_price_dict(atmSP, wingCall, wingPut, current_datetime_str_short, row.closest_expiry, i, df) \n",
    "        if position == 'hold':\n",
    "            if row.signal == 'Buy':\n",
    "                if row.rsi < 70 and row.ama < row.Close:\n",
    "                    # buy atmSp call -> api call # Sell atmSp put -> api call # buy wingCall -> api call # buy wingPut -> api call\n",
    "                    df.at[i, 'position'] = position = 'buy'\n",
    "                    has_traded_today = True\n",
    "            \n",
    "            elif row.signal == 'Sell':\n",
    "                if row.rsi > 30 and row.ama > row.Close:\n",
    "                    # sell atmSp call -> api call # buy atmSp put -> api call # Buy wingPut -> api call # Buy wingCall -> api call\n",
    "                    df.at[i, 'position'] = position = 'sell'\n",
    "                    has_traded_today = True\n",
    "\n",
    "        elif position == 'buy':\n",
    "            if row.signal == 'Hold':\n",
    "                if row.rsi > 70:\n",
    "                    # buy atmSp put -> api call x 2 # sell wingPut -> api call x 2 # sell wingCall -> api call x 2\n",
    "                    df.at[i, 'position'] = position = 'squareoff'\n",
    "                    has_traded_today = True\n",
    "            \n",
    "            elif row.signal == 'Sell':          \n",
    "                # buy atmSp put -> api call # sell wingPut -> api call # sell wingCall -> api call\n",
    "                df.at[i, 'position'] = position =  'squareoff'\n",
    "                has_traded_today = True\n",
    "\n",
    "        elif position == 'sell':\n",
    "            if row.signal == 'Hold':\n",
    "                if row.rsi < 30:              \n",
    "                    # buy atmSp call -> api call # sell wingPut -> api call # sell wingCall -> api call  \n",
    "                    df.at[i, 'position'] = position = 'squareoff'\n",
    "                    has_traded_today = True\n",
    "\n",
    "                    \n",
    "            elif row.signal == 'Buy':\n",
    "                df.at[df.index[i], 'position'] = position = 'squareoff'\n",
    "                has_traded_today = True\n",
    "                \n",
    "\n",
    "        df.at[i, 'position'] = position\n",
    "        df.loc[i, ['atmSP', 'wingCall', 'wingPut', 'legPriceOrignal1', 'legPriceOrignal2', 'legPriceOrignal3', 'legPriceOrignal4']] = [atmSP, wingCall, wingPut, close_price_dict['atmSPCall'], close_price_dict['atmSPPut'], close_price_dict['wingCallPrice'], close_price_dict['wingPutPrice']]\n",
    "\n",
    "\n",
    "        if not has_traded_today:\n",
    "            df.at[i, 'position'] = df.at[i-1, 'position']\n",
    "\n",
    "        calculate_m2m_new(i, caller='daily')\n",
    "        \n",
    "        if df.at[i, 'cumReturns'] > highest_m2m:\n",
    "            highest_m2m = df.at[i, 'cumReturns']\n",
    "\n",
    "        df.at[i, 'stoploss'] = stoploss_price = highest_m2m - (100000*0.03)\n",
    "        # called everytime\n",
    "        \n",
    "\n",
    "        if df.at[i, 'cumReturns'] < stoploss_price:\n",
    "            logging.info(f\" Stoploss hit at {current_datetime_str}\")\n",
    "            # squareoff all positions\n",
    "            df.loc[i, squareoff_columns_reset] = 0\n",
    "            df.at[i, 'position'] = position = 'hard-squareoff'\n",
    "            calculate_m2m_new(i, caller='stoploss')\n",
    "            highest_m2m = df.at[i, 'cumReturns']\n",
    "            # df.at[i, 'totalPL'] = -3300\n",
    "            # df.at[i, 'balance'] = df.at[i-1, 'balance'] - 3300\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "    # timer_end = tm.time()\n",
    "    # logging.info(f\"Time taken for this iteration: {timer_end - timer_start} seconds\")\n",
    "\n",
    "\n",
    "    # df.at[df.index[i], 'position'] = position\n",
    "\n",
    "\n",
    "save_data()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
